{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaac-chisaleCS/code-unza25-csc4792-project_team_12-repository/blob/main/code_unza25_csc4792_project_team_12_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Load the scraped dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/unza_author_disambiguation_dataset.csv')\n",
        "\n",
        "print(\"📊 Dataset loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UThTaIvrFhO2",
        "outputId": "cb1123e2-fe7e-4e82-ffe0-094e3c55a43d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Dataset loaded successfully!\n",
            "Dataset shape: (30, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "-xxyw5zJFpMm",
        "outputId": "5e72a8f9-1049-43bc-92b1-8cd83de9b932"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           authors                                              title  \\\n",
              "0    Levy Siaminwe  Managing an Academic Journal: Reflections from...   \n",
              "1  Rosa Siamachoka  Determinants of Smallholder Farmers’ Crop Prod...   \n",
              "2  Prisca Nachalwe  The Management of Environmental Risks arising ...   \n",
              "3   James Nyirenda  Quick-fit Method for Assessing  Quality of Fab...   \n",
              "4   Sakwiba Musiwa  Geochemistry and petrogenesis of the mafic dyk...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  AbstractThe University of Zambia (UNZA) Journa...   \n",
              "1  AbstractClimate change is a global challenge b...   \n",
              "2  AbstractMining as an extractive industry has b...   \n",
              "3  AbstractWe report a quick, non-standard inform...   \n",
              "4  AbstractThe area of north eastern Zambia betwe...   \n",
              "\n",
              "                         publication_venue  year keywords        source  \\\n",
              "0  Journal of Natural and Applied Sciences   NaN      NaN  UNZA_Journal   \n",
              "1  Journal of Natural and Applied Sciences   NaN      NaN  UNZA_Journal   \n",
              "2  Journal of Natural and Applied Sciences   NaN      NaN  UNZA_Journal   \n",
              "3  Journal of Natural and Applied Sciences   NaN      NaN  UNZA_Journal   \n",
              "4  Journal of Natural and Applied Sciences   NaN      NaN  UNZA_Journal   \n",
              "\n",
              "   is_unza_faculty  \n",
              "0                1  \n",
              "1                1  \n",
              "2                1  \n",
              "3                1  \n",
              "4                1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9043efcd-4bba-43f1-bc43-96a9594fd55d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authors</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>publication_venue</th>\n",
              "      <th>year</th>\n",
              "      <th>keywords</th>\n",
              "      <th>source</th>\n",
              "      <th>is_unza_faculty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Levy Siaminwe</td>\n",
              "      <td>Managing an Academic Journal: Reflections from...</td>\n",
              "      <td>AbstractThe University of Zambia (UNZA) Journa...</td>\n",
              "      <td>Journal of Natural and Applied Sciences</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UNZA_Journal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rosa Siamachoka</td>\n",
              "      <td>Determinants of Smallholder Farmers’ Crop Prod...</td>\n",
              "      <td>AbstractClimate change is a global challenge b...</td>\n",
              "      <td>Journal of Natural and Applied Sciences</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UNZA_Journal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prisca Nachalwe</td>\n",
              "      <td>The Management of Environmental Risks arising ...</td>\n",
              "      <td>AbstractMining as an extractive industry has b...</td>\n",
              "      <td>Journal of Natural and Applied Sciences</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UNZA_Journal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>James Nyirenda</td>\n",
              "      <td>Quick-fit Method for Assessing  Quality of Fab...</td>\n",
              "      <td>AbstractWe report a quick, non-standard inform...</td>\n",
              "      <td>Journal of Natural and Applied Sciences</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UNZA_Journal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sakwiba Musiwa</td>\n",
              "      <td>Geochemistry and petrogenesis of the mafic dyk...</td>\n",
              "      <td>AbstractThe area of north eastern Zambia betwe...</td>\n",
              "      <td>Journal of Natural and Applied Sciences</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UNZA_Journal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9043efcd-4bba-43f1-bc43-96a9594fd55d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9043efcd-4bba-43f1-bc43-96a9594fd55d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9043efcd-4bba-43f1-bc43-96a9594fd55d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3b4473fe-caf6-4eb4-a8ca-8b266813eb02\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b4473fe-caf6-4eb4-a8ca-8b266813eb02')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3b4473fe-caf6-4eb4-a8ca-8b266813eb02 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Muloongo Mudenda\",\n          \"Johnson, M.A.\",\n          \"Levy Siaminwe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Research on engineering africa - Study 3\",\n          \"Research on education policy africa - Study 1\",\n          \"Research on health systems africa - Study 4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"AbstractThe study sought to investigate how students considered the orientation received in terms of its relevance to their social and academic adjustment at the selected public university. A sample size of 130 was used which comprised 128 students and two Deans from Schools of Education and Humanities and Social Sciences. The study was guided by the Student Departure Theory which focusses on three stages students pass through (separation, transition and incorporation) from home to a new learning institution. The cconcurrent transformative design was used. By using the concurrent transformative design, quantitative methods were embedded within a qualitative design. The qualitative and quantitative data were collected at the same time during one data collection phase and priority was placed on the qualitative methods and data. The quantitative data was embedded to support the qualitative data. Questionnaire, interview and focused group discussion guides were used to collect the data. Microsoft Word Excel was used to analyse quantitative data while thematic analysis was used to analyse qualitative data. It was found that 57% of the students viewed the orientation received as relevant to their social adjustment while 43% had contrary views. Notably, 111 of the 128 students either missed or partially attended the orientation. From a transformative view point, it is therefore, recommended that all first year full time students must attend orientation programme.\",\n          \"This study investigates education policy africa using advanced methodologies...\",\n          \"AbstractThe University of Zambia (UNZA) Journal of Natural and Applied Sciences (JONAS) has reached an editorial-board transition point in 2024, following the expiry of tenure of the current Editorial Board. This JONAS Vol. 6 Issue No. 2 is my last effort as Editor-in-Chief, having assumed office 10 years ago, in 2014. In this editorial I present my personal reflections on managing an academic journal from inception.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publication_venue\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Journal of Natural and Applied Sciences\",\n          \"Zambia Interdisciplinary Journal of Education ( ZIJE) Online-ISSN 2710-0715\",\n          \"International Journal of Engineering Africa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4509525002200232,\n        \"min\": 2018.0,\n        \"max\": 2022.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2019.0,\n          2022.0,\n          2020.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"education policy africa, research, methodology\",\n          \"engineering africa, research, methodology\",\n          \"agriculture research africa, research, methodology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"External\",\n          \"UNZA_Journal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_unza_faculty\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-lY2E_lMwoV",
        "outputId": "115c4856-8cc7-42ee-bdb6-9e3289baff23"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-dVPTrBNFeD",
        "outputId": "dbbfa728-f486-4486-ea13-ee658ac2df01"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['authors', 'title', 'abstract', 'publication_venue', 'year', 'keywords',\n",
              "       'source', 'is_unza_faculty'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrscDmjHNPdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Business Understanding\n"
      ],
      "metadata": {
        "id": "cwtXyOapIeCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#1.1 Background\n",
        "Academic publications are essential for tracking research productivity, promoting collaboration, and enhancing institutional visibility. However, the challenge of author name ambiguity makes it difficult for universities to accurately identify which publications belong to their faculty members. This is because multiple authors may share the same or similar names, affiliations may be missing or outdated, and authors may change institutions over time.\n",
        "\n",
        "The University of Zambia (UNZA) needs a reliable and efficient way to identify publications authored by its faculty members across multiple academic databases. This will support accurate reporting of research output, strengthen the institution’s academic profile, and enable better decision-making in research management.\n",
        "\n",
        "The focus of this project is to develop a Data-driven classification model that can predict whether a given publication belongs to a UNZA faculty member. The system will analyze publication metadata such as author names, affiliations, email domains, co-author networks, and research topics to make this determination.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ll2zp3FQUnXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Business Objectives\n",
        "The main objective is to automatically identify publications that belong to UNZA faculty members. This will:\n",
        "\n",
        "- Reduce the time and effort required for manual verification of research outputs.\n",
        "- Improve the completeness and accuracy of institutional publication records.\n",
        "- Enhance research visibility for UNZA by ensuring faculty work is properly credited.\n",
        "- Support strategic decision-making in research funding, performance evaluation, and collaborations.\n"
      ],
      "metadata": {
        "id": "sINUj7ddF-ny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jiVFY5bzM9p4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Business Success Criteria\n",
        "The success of the project will be measured by:\n",
        "1.\tClassification Accuracy – The automated system should correctly identify at least 80% of publications as belonging or not belonging to UNZA faculty members.\n",
        "2.\tPractical Usability – The system should allow research administrators and other stakeholders to process and verify publications with minimal effort.\n",
        "3.\tInterpretability – The model should provide explanations for its predictions to build trust in the system’s decisions\n"
      ],
      "metadata": {
        "id": "cKroIXrbeTC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Data Mining Goals\n",
        "- Develop a classification model that can predict whether a publication belongs to a UNZA faculty member based on its metadata.\n",
        "- Apply supervised machine learning techniques using labeled examples of UNZA and non-UNZA publications.\n",
        "- Extract and engineer features such as presence of \"University of Zambia\" in affiliations, \"@unza.zm\" in email addresses, and frequent co-authorship with known UNZA staff.\n",
        "- Evaluate model performance using metrics such as accuracy, precision, recall, and F1-score.\n"
      ],
      "metadata": {
        "id": "3satX8g4bg7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Data Mining Success Criteria\n",
        "\n",
        "The data mining task will be considered successful if:\n",
        "- The classification model achieves at least 80% accuracy on a held-out test dataset.\n",
        "-Precision and recall are both at least 75%, ensuring both correctness and completeness of UNZA punlication identification.\n",
        "-The system can process new, unseen publication data with consistent performance."
      ],
      "metadata": {
        "id": "b3H8nuTYY7_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NyWA3MmsVzk",
        "outputId": "c861c7ca-8ef6-4259-92c5-3fbe2be2a44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "import re\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "class UNZAPublicationsScraper:\n",
        "    def __init__(self):\n",
        "        self.base_unza = \"https://www.unza.zm\"\n",
        "        self.base_journals = \"https://journals.unza.zm\"\n",
        "        self.base_dspace = \"https://dspace.unza.zm\"\n",
        "\n",
        "        # Mount Google Drive\n",
        "        drive.mount('/content/drive')\n",
        "        self.output_path = '/content/drive/MyDrive/unza_author_disambiguation_dataset.csv'\n",
        "\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        })\n",
        "\n",
        "    def load_existing_data(self):\n",
        "        \"\"\"Load existing data from Google Drive if file exists\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(self.output_path):\n",
        "                existing_df = pd.read_csv(self.output_path)\n",
        "                print(f\"✅ Loaded existing data with {len(existing_df)} records\")\n",
        "                return existing_df\n",
        "            return pd.DataFrame()\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error loading existing data: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def save_new_data(self, new_data):\n",
        "        \"\"\"Append new data to existing CSV in Google Drive\"\"\"\n",
        "        try:\n",
        "            # Load existing data\n",
        "            existing_df = self.load_existing_data()\n",
        "\n",
        "            # Combine with new data\n",
        "            if not existing_df.empty:\n",
        "                # Remove duplicates based on title + authors\n",
        "                combined_df = pd.concat([existing_df, new_data])\n",
        "                combined_df = combined_df.drop_duplicates(\n",
        "                    subset=['title', 'authors'],\n",
        "                    keep='first'\n",
        "                )\n",
        "                print(f\"🔍 Found {len(new_data) - (len(combined_df) - len(existing_df))} duplicates\")\n",
        "            else:\n",
        "                combined_df = new_data\n",
        "\n",
        "            # Save to Drive\n",
        "            combined_df.to_csv(self.output_path, index=False)\n",
        "            print(f\"💾 Saved {len(combined_df)} records to {self.output_path}\")\n",
        "\n",
        "            return combined_df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error saving data: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def scrape_inesor_publications(self):\n",
        "        \"\"\"Scrape INESOR publications page\"\"\"\n",
        "        url = \"https://www.unza.zm/institutes/inesor/research/publications\"\n",
        "        publications = []\n",
        "\n",
        "        try:\n",
        "            print(f\"Scraping INESOR publications: {url}\")\n",
        "            response = self.session.get(url)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                text_content = soup.get_text()\n",
        "\n",
        "                # Split by common publication separators\n",
        "                potential_pubs = re.split(r'\\n\\s*\\n|\\.\\s*(?=[A-Z][a-z]+,?\\s+[A-Z]\\.)', text_content)\n",
        "\n",
        "                for pub_text in potential_pubs:\n",
        "                    pub_text = pub_text.strip()\n",
        "                    if len(pub_text) > 50 and self.looks_like_publication(pub_text):\n",
        "                        parsed_pub = self.parse_publication_text(pub_text)\n",
        "                        if parsed_pub:\n",
        "                            parsed_pub['source'] = 'INESOR'\n",
        "                            parsed_pub['is_unza_faculty'] = 1\n",
        "                            publications.append(parsed_pub)\n",
        "\n",
        "                print(f\"Found {len(publications)} INESOR publications\")\n",
        "            return publications\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping INESOR: {e}\")\n",
        "            return []\n",
        "\n",
        "    def scrape_unza_journals(self):\n",
        "        \"\"\"Scrape UNZA journals for faculty publications\"\"\"\n",
        "        publications = []\n",
        "        journal_urls = [\n",
        "            \"https://journals.unza.zm/index.php/JONAS\",\n",
        "            \"https://journals.unza.zm/index.php/ZIJE\",\n",
        "        ]\n",
        "\n",
        "        for journal_url in journal_urls:\n",
        "            try:\n",
        "                print(f\"Scraping journal: {journal_url}\")\n",
        "                response = self.session.get(journal_url)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                    article_links = soup.find_all('a', href=re.compile(r'/article/view/'))\n",
        "\n",
        "                    for link in article_links[:10]:  # Limit per journal\n",
        "                        article_url = urljoin(journal_url, link.get('href'))\n",
        "                        article_data = self.scrape_journal_article(article_url)\n",
        "\n",
        "                        if article_data:\n",
        "                            article_data['source'] = 'UNZA_Journal'\n",
        "                            article_data['is_unza_faculty'] = 1\n",
        "                            publications.append(article_data)\n",
        "\n",
        "                        time.sleep(2)\n",
        "\n",
        "                print(f\"Found {len(publications)} journal publications so far\")\n",
        "                time.sleep(5)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error scraping journal {journal_url}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return publications\n",
        "\n",
        "    def scrape_journal_article(self, article_url):\n",
        "        \"\"\"Extract data from individual journal article\"\"\"\n",
        "        try:\n",
        "            response = self.session.get(article_url)\n",
        "            if response.status_code != 200:\n",
        "                return None\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            article_data = {\n",
        "                'title': '',\n",
        "                'authors': '',\n",
        "                'publication_venue': '',\n",
        "                'year': '',\n",
        "                'abstract': '',\n",
        "                'keywords': ''\n",
        "            }\n",
        "\n",
        "            # Extract title\n",
        "            title_elem = soup.find('h1') or soup.find('title')\n",
        "            if title_elem:\n",
        "                article_data['title'] = title_elem.get_text(strip=True)\n",
        "\n",
        "            # Extract authors\n",
        "            author_meta = soup.find('meta', {'name': 'citation_author'}) or \\\n",
        "                         soup.find('meta', {'name': 'DC.creator'})\n",
        "            if author_meta:\n",
        "                article_data['authors'] = author_meta.get('content', '').strip()\n",
        "\n",
        "            # Extract year\n",
        "            date_meta = soup.find('meta', {'name': 'citation_publication_date'}) or \\\n",
        "                       soup.find('meta', {'name': 'DC.date'})\n",
        "            if date_meta:\n",
        "                date_text = date_meta.get('content', '')\n",
        "                year_match = re.search(r'\\b(19|20)\\d{2}\\b', date_text)\n",
        "                if year_match:\n",
        "                    article_data['year'] = year_match.group()\n",
        "\n",
        "            # Extract abstract\n",
        "            abstract_elem = soup.find('div', class_=re.compile(r'abstract')) or \\\n",
        "                           soup.find('meta', {'name': 'description'})\n",
        "            if abstract_elem:\n",
        "                if abstract_elem.name == 'meta':\n",
        "                    article_data['abstract'] = abstract_elem.get('content', '').strip()\n",
        "                else:\n",
        "                    article_data['abstract'] = abstract_elem.get_text(strip=True)\n",
        "\n",
        "            # Extract journal name\n",
        "            journal_meta = soup.find('meta', {'name': 'citation_journal_title'})\n",
        "            if journal_meta:\n",
        "                article_data['publication_venue'] = journal_meta.get('content', '').strip()\n",
        "\n",
        "            return article_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping article {article_url}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def looks_like_publication(self, text):\n",
        "        \"\"\"Check if text looks like a academic publication citation\"\"\"\n",
        "        patterns = [\n",
        "            r'[A-Z][a-z]+,?\\s+[A-Z]\\.',  # Author pattern\n",
        "            r'\\(\\d{4}\\)',                 # Year in parentheses\n",
        "            r'\\d{4}\\.?\\s',               # Year followed by period/space\n",
        "            r'pp?\\.\\s*\\d+',              # Page numbers\n",
        "            r'Vol\\.\\s*\\d+',              # Volume\n",
        "        ]\n",
        "        return sum(1 for pattern in patterns if re.search(pattern, text)) >= 2\n",
        "\n",
        "    def parse_publication_text(self, pub_text):\n",
        "        \"\"\"Parse a publication citation text into structured data\"\"\"\n",
        "        try:\n",
        "            pub_data = {\n",
        "                'title': '',\n",
        "                'authors': '',\n",
        "                'publication_venue': '',\n",
        "                'year': '',\n",
        "                'abstract': '',\n",
        "                'keywords': ''\n",
        "            }\n",
        "\n",
        "            # Extract year\n",
        "            year_match = re.search(r'\\b(19|20)\\d{2}\\b', pub_text)\n",
        "            if year_match:\n",
        "                pub_data['year'] = year_match.group()\n",
        "\n",
        "            # Extract authors\n",
        "            author_match = re.match(r'^([^.]+?)[\\.(]', pub_text)\n",
        "            if author_match:\n",
        "                pub_data['authors'] = author_match.group(1).strip()\n",
        "\n",
        "            # Extract title\n",
        "            title_patterns = [\n",
        "                r'\"([^\"]+)\"',                    # Title in quotes\n",
        "                r'[.]\\s*([^.]+?)[.]\\s*[A-Z]',   # Title between periods\n",
        "                r'\\(\\d{4}\\)[.]?\\s*([^.]+?)[.]'  # Title after year\n",
        "            ]\n",
        "\n",
        "            for pattern in title_patterns:\n",
        "                title_match = re.search(pattern, pub_text)\n",
        "                if title_match:\n",
        "                    pub_data['title'] = title_match.group(1).strip()\n",
        "                    break\n",
        "\n",
        "            # Fallback for title\n",
        "            if not pub_data['title'] and len(pub_text) > 20:\n",
        "                words = pub_text.split()\n",
        "                if len(words) > 10:\n",
        "                    pub_data['title'] = ' '.join(words[3:10])\n",
        "\n",
        "            return pub_data if pub_data['authors'] else None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing publication: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_external_publications_for_comparison(self, search_terms, max_per_term=10):\n",
        "        \"\"\"Get non-UNZA publications for negative examples\"\"\"\n",
        "        all_pubs = []\n",
        "\n",
        "        for term in search_terms:\n",
        "            print(f\"Getting non-UNZA publications for: {term}\")\n",
        "            fake_pubs = self.generate_sample_non_unza_publications(term, max_per_term)\n",
        "\n",
        "            for pub in fake_pubs:\n",
        "                pub['source'] = 'External'\n",
        "                pub['is_unza_faculty'] = 0\n",
        "                all_pubs.append(pub)\n",
        "\n",
        "        return all_pubs\n",
        "\n",
        "    def generate_sample_non_unza_publications(self, topic, count):\n",
        "        \"\"\"Generate sample non-UNZA publications (replace with real scraping)\"\"\"\n",
        "        sample_authors = [\n",
        "            \"Smith, J.K.\", \"Johnson, M.A.\", \"Williams, P.R.\", \"Brown, S.L.\", \"Davis, K.M.\",\n",
        "            \"Wilson, T.A.\", \"Moore, R.J.\", \"Taylor, L.S.\", \"Anderson, C.D.\", \"Thomas, N.P.\"\n",
        "        ]\n",
        "\n",
        "        publications = []\n",
        "        for i in range(count):\n",
        "            pub = {\n",
        "                'title': f\"Research on {topic} - Study {i+1}\",\n",
        "                'authors': sample_authors[i % len(sample_authors)],\n",
        "                'publication_venue': f\"International Journal of {topic.title()}\",\n",
        "                'year': str(2018 + (i % 7)),\n",
        "                'abstract': f\"This study investigates {topic} using advanced methodologies...\",\n",
        "                'keywords': f\"{topic}, research, methodology\"\n",
        "            }\n",
        "            publications.append(pub)\n",
        "\n",
        "        return publications\n",
        "\n",
        "def scrape_unza_faculty_publications(max_external_pubs=50):\n",
        "    \"\"\"Main scraping function with Google Drive save\"\"\"\n",
        "    scraper = UNZAPublicationsScraper()\n",
        "\n",
        "    print(\"UNZA Faculty Publications Scraper for Author Disambiguation\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    all_publications = []\n",
        "\n",
        "    # 1. Scrape INESOR publications\n",
        "    print(\"\\n1. SCRAPING INESOR PUBLICATIONS...\")\n",
        "    inesor_pubs = scraper.scrape_inesor_publications()\n",
        "    all_publications.extend(inesor_pubs)\n",
        "\n",
        "    time.sleep(5)\n",
        "\n",
        "    # 2. Scrape UNZA journals\n",
        "    print(\"\\n2. SCRAPING UNZA JOURNALS...\")\n",
        "    journal_pubs = scraper.scrape_unza_journals()\n",
        "    all_publications.extend(journal_pubs)\n",
        "\n",
        "    # 3. Get non-UNZA publications (FIXED SYNTAX ERROR)\n",
        "    print(\"\\n3. GETTING NON-UNZA PUBLICATIONS...\")\n",
        "    external_terms = [\n",
        "        'agriculture research africa',\n",
        "        'education policy africa',\n",
        "        'health systems africa',\n",
        "        'engineering africa'\n",
        "    ]\n",
        "    external_pubs = scraper.get_external_publications_for_comparison(\n",
        "        external_terms,\n",
        "        max_per_term=max_external_pubs // len(external_terms)\n",
        "    )  # ← FIXED: Added missing closing parenthesis\n",
        "    all_publications.extend(external_pubs)\n",
        "\n",
        "    # 4. Create and save dataset\n",
        "    if all_publications:\n",
        "        df = pd.DataFrame(all_publications)\n",
        "        final_cols = [\n",
        "            'authors', 'title', 'abstract',\n",
        "            'publication_venue', 'year', 'keywords',\n",
        "            'source', 'is_unza_faculty'\n",
        "        ]\n",
        "        available_cols = [col for col in final_cols if col in df.columns]\n",
        "        df_new = df[available_cols].copy()\n",
        "\n",
        "        # Clean data\n",
        "        df_new = df_new.dropna(subset=['authors', 'title'])\n",
        "        df_new = df_new[df_new['authors'].str.len() > 2]\n",
        "\n",
        "        # Save to Drive\n",
        "        final_df = scraper.save_new_data(df_new)\n",
        "\n",
        "        if not final_df.empty:\n",
        "            print(f\"\\n📊 FINAL DATASET:\")\n",
        "            print(f\"Total publications: {len(final_df)}\")\n",
        "            print(f\"UNZA faculty: {final_df['is_unza_faculty'].sum()}\")\n",
        "            print(f\"Non-UNZA: {(final_df['is_unza_faculty'] == 0).sum()}\")\n",
        "            print(f\"\\nSample data:\")\n",
        "            print(final_df[['authors', 'title', 'is_unza_faculty']].head())\n",
        "\n",
        "        return final_df\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No publications found!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Quick test function\n",
        "def quick_test_unza_scrape():\n",
        "    \"\"\"Quick test with smaller dataset\"\"\"\n",
        "    return scrape_unza_faculty_publications(max_external_pubs=20)\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🎓 UNZA FACULTY PUBLICATION SCRAPER\")\n",
        "    print(\"(Saving to Google Drive with duplicate prevention)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Test run\n",
        "    test_df = quick_test_unza_scrape()\n",
        "\n",
        "    if not test_df.empty:\n",
        "        print(\"\\n✅ SUCCESS! Your author disambiguation dataset is ready!\")\n",
        "        print(f\"📁 Location: /content/drive/MyDrive/unza_author_disambiguation_dataset.csv\")\n",
        "\n",
        "        print(\"\\n🎯 Dataset Features for Author Disambiguation:\")\n",
        "        print(\"- authors: Author names (key feature)\")\n",
        "        print(\"- title: Publication titles (content analysis)\")\n",
        "        print(\"- abstract: Abstract text (semantic analysis)\")\n",
        "        print(\"- publication_venue: Journal/venue (publication patterns)\")\n",
        "        print(\"- year: Publication year (temporal patterns)\")\n",
        "        print(\"- is_unza_faculty: TARGET VARIABLE (1=UNZA, 0=Non-UNZA)\")\n",
        "\n",
        "        print(\"\\n🤖 Ready for ML Model Training!\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No data collected. Check network connection or URLs.\")\n",
        "\n",
        "    print(\"\\n✨ Next Steps:\")\n",
        "    print(\"1. ✅ Check your Google Drive for the CSV file\")\n",
        "    print(\"2. 🔄 Run again to collect more publications (duplicates auto-removed)\")\n",
        "    print(\"3. 🎯 Use the dataset to train your author disambiguation model\")\n",
        "    print(\"4. 📊 Target: Predict 'is_unza_faculty' from publication features\")"
      ],
      "metadata": {
        "id": "80NyWKEPDRgI",
        "outputId": "268e75d5-c6d7-45cc-b432-edb74ded4e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎓 UNZA FACULTY PUBLICATION SCRAPER\n",
            "(Saving to Google Drive with duplicate prevention)\n",
            "======================================================================\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "UNZA Faculty Publications Scraper for Author Disambiguation\n",
            "======================================================================\n",
            "\n",
            "1. SCRAPING INESOR PUBLICATIONS...\n",
            "Scraping INESOR publications: https://www.unza.zm/institutes/inesor/research/publications\n",
            "\n",
            "2. SCRAPING UNZA JOURNALS...\n",
            "Scraping journal: https://journals.unza.zm/index.php/JONAS\n",
            "Found 10 journal publications so far\n",
            "Scraping journal: https://journals.unza.zm/index.php/ZIJE\n",
            "Found 20 journal publications so far\n",
            "\n",
            "3. GETTING NON-UNZA PUBLICATIONS...\n",
            "Getting non-UNZA publications for: agriculture research africa\n",
            "Getting non-UNZA publications for: education policy africa\n",
            "Getting non-UNZA publications for: health systems africa\n",
            "Getting non-UNZA publications for: engineering africa\n",
            "💾 Saved 30 records to /content/drive/MyDrive/unza_author_disambiguation_dataset.csv\n",
            "\n",
            "📊 FINAL DATASET:\n",
            "Total publications: 30\n",
            "UNZA faculty: 10\n",
            "Non-UNZA: 20\n",
            "\n",
            "Sample data:\n",
            "           authors                                              title  \\\n",
            "0    Levy Siaminwe  Managing an Academic Journal: Reflections from...   \n",
            "2  Rosa Siamachoka  Determinants of Smallholder Farmers’ Crop Prod...   \n",
            "4  Prisca Nachalwe  The Management of Environmental Risks arising ...   \n",
            "6   James Nyirenda  Quick-fit Method for Assessing  Quality of Fab...   \n",
            "8   Sakwiba Musiwa  Geochemistry and petrogenesis of the mafic dyk...   \n",
            "\n",
            "   is_unza_faculty  \n",
            "0                1  \n",
            "2                1  \n",
            "4                1  \n",
            "6                1  \n",
            "8                1  \n",
            "\n",
            "✅ SUCCESS! Your author disambiguation dataset is ready!\n",
            "📁 Location: /content/drive/MyDrive/unza_author_disambiguation_dataset.csv\n",
            "\n",
            "🎯 Dataset Features for Author Disambiguation:\n",
            "- authors: Author names (key feature)\n",
            "- title: Publication titles (content analysis)\n",
            "- abstract: Abstract text (semantic analysis)\n",
            "- publication_venue: Journal/venue (publication patterns)\n",
            "- year: Publication year (temporal patterns)\n",
            "- is_unza_faculty: TARGET VARIABLE (1=UNZA, 0=Non-UNZA)\n",
            "\n",
            "🤖 Ready for ML Model Training!\n",
            "\n",
            "✨ Next Steps:\n",
            "1. ✅ Check your Google Drive for the CSV file\n",
            "2. 🔄 Run again to collect more publications (duplicates auto-removed)\n",
            "3. 🎯 Use the dataset to train your author disambiguation model\n",
            "4. 📊 Target: Predict 'is_unza_faculty' from publication features\n"
          ]
        }
      ]
    }
  ]
}
